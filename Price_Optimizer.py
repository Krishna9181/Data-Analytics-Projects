# -*- coding: utf-8 -*-
"""Retail_Pricing_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/154L63pc5nVBr_mOw5jUFx5Jbv-5QBXSl
"""
## Adding new line
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import seaborn as sns
from datetime import datetime

df = pd.read_csv("data.csv", encoding = "utf-8")

"""**Pre-Processing**"""

df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')
df['month'] = df['date'].dt.month
#df['month'] = df['month'].astype('category')

df['cost'] = df['cost']*0.01

df.drop_duplicates(inplace=True)
df.dropna(inplace = True)

df_test = df

"""**Data Spiltting**"""

X = df[['sku_id', 'gender', 'price_tier', 'price', 'cost', 'month']]
Y = df['sales']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 15, train_size = 0.70)

X_train = pd.get_dummies(X_train, columns=['gender', 'price_tier', 'month'])
X_test = pd.get_dummies(X_test, columns = ['gender', 'price_tier', 'month'])

"""**Normalization**"""

def normalize(col):
  col = (col-col.min())/(col.max() - col.min())
  return col

def denormalize(col):
  col = (col * (col.max() - col.min())) + col.min()
  return col

cols_to_norm = ['price', 'cost']
X_train[cols_to_norm] = X_train[cols_to_norm].agg(normalize)
X_test[cols_to_norm] = X_test[cols_to_norm].agg(normalize)


"""**ANN Model**"""

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout

model = Sequential()
model.add(Dense(units = 4, kernel_initializer = "glorot_uniform", activation = "relu"))
model.add(Dropout(0))
model.add(Dense(units = 4, kernel_initializer = "glorot_uniform", activation = "relu"))
model.add(Dropout(0))
model.add(Dense(units = 1, kernel_initializer = "glorot_uniform", activation = "relu"))

model.compile(optimizer = "adam", loss = "mean_squared_error", metrics= ['R2Score'])

model.fit(X_train, Y_train, epochs = 15, batch_size = 50, verbose=False)
print("")
Validation_loss = model.evaluate(X_test, Y_test, batch_size = 50, verbose=False)
print("Validation Loss: ", Validation_loss)

Y_predict = model.predict(X_test, verbose = False)

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(Y_test, Y_predict)
print(mse)

predictions = model.predict(X_test.iloc[[1500]], verbose = False)
print(predictions)

"""**Main Function**"""

def RecommendPrice(itemID, data, Time, Date):
  df2 = pd.read_csv(data)

  df2['cost'] = df2['cost']*0.01
  df2.drop_duplicates(inplace=True)
  df2.dropna(inplace = True)
  #date_object = datetime.strptime(Date, '%Y-%m-%d')
  #month = date_object.month
  df2['date'] = pd.to_datetime(df2['date'], format='%d-%m-%Y')
  #df2['date'] = pd.to_datetime(df2['date'])
  df2['month'] = df2['date'].dt.month
  df_new = df2[['sku_id', 'gender', 'price_tier', 'price', 'cost', 'month']]
  df_new = pd.get_dummies(df_new, columns=['gender', 'price_tier', 'month'])
  df_new = df_new[df_new['sku_id'] == itemID]
  #print(df_new.head())
  #print(df_new.shape)
  sales_predictions = model.predict(df_new, verbose = False)
  df_new['sales_predicted'] = sales_predictions
  df_new['profit'] = (df_new['price'] - df_new['cost'])*df_new['sales_predicted']
  df_new = df_new.sort_values(by = 'profit', ascending = False)
  profitable_price = df_new.iloc[0]['price']
  return profitable_price

# Example usage
filepath = 'data.csv'
item_id = 10
profitable_price = RecommendPrice(item_id, filepath, '22:00:00', '2020-05-24')
print("Profitable Price: ", profitable_price)
